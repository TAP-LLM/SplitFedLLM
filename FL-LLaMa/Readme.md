# FL-LLaMA
![transformers](https://img.shields.io/badge/transformers->=4.38.0-greene)
![License](https://img.shields.io/badge/license-MIT-yellow)  
![Python](https://img.shields.io/badge/Python->=3.10.4-blue)  
 Read this in [English](README_en.md)

## æ”¯æŒçš„æ¨¡å‹
| Model            | Type | Download                                                                                                                                |
|------------------|------|-----------------------------------------------------------------------------------------------------------------------------------------|                                                                                                                                                                                         
| Llama-2-7b-hf    | Base | [ğŸ¤— Huggingface](https://huggingface.co/meta-llama/Llama-2-7b-hf)  |
| Llama-2-7b-chat-hf | Chat | [ğŸ¤— Huggingface](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)                                                                                                                                                                                          |

## å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–é¡¹
```bash
git clone https://github.com/TAP-LLM/SplitFedLLM.git
cd SplitFedLLM/FL-LLaMa
pip install -r requirements.txt
```
### æ•°æ®å‡†å¤‡
1. SuperGLUE Benchmark
ä»»åŠ¡ç±»å‹ï¼šè‡ªç„¶è¯­è¨€ç†è§£ï¼ˆNLUï¼‰ï¼ŒåŒ…å« 8 ä¸ªå­ä»»åŠ¡ï¼Œè¦†ç›–å¸¸è¯†æ¨ç†ã€è¯­ä¹‰è§£æç­‰å¤æ‚è¯­è¨€æŒ‘æˆ˜ã€‚
æ•°æ®é›†è¯¦æƒ…ï¼š
ReCoRDï¼šé€šè¿‡æ¶ˆè§£æ®µè½ä¸­çš„æ­§ä¹‰å®ä½“è¯„ä¼°é˜…è¯»ç†è§£èƒ½åŠ›ã€‚
COPAï¼šé€šè¿‡é€‰æ‹©å‰æçš„æ›´å¯èƒ½åŸå› æˆ–ç»“æœè¯„ä¼°å› æœæ¨ç†èƒ½åŠ›ã€‚
WSCï¼šé€šè¿‡ä»£è¯æ¶ˆè§£è¯„ä¼°æ·±åº¦ä¸Šä¸‹æ–‡ç†è§£èƒ½åŠ›ã€‚
RTEï¼šé€šè¿‡åˆ¤æ–­å¥å­é—´çš„è•´å«ã€çŸ›ç›¾æˆ–æ— å…³å…³ç³»è¯„ä¼°æ–‡æœ¬è•´å«èƒ½åŠ›ã€‚
BoolQï¼šåŸºäºä¸Šä¸‹æ–‡å›ç­”æ˜¯ / å¦é—®é¢˜ã€‚
WiCï¼šé€šè¿‡åˆ¤æ–­å•è¯åœ¨ä¸¤ä¸ªå¥å­ä¸­çš„å«ä¹‰æ˜¯å¦ç›¸åŒè¯„ä¼°è¯ä¹‰æ¶ˆæ­§èƒ½åŠ›ã€‚
CBï¼šå¤„ç†å¤æ‚å¥å­ä¸­çš„è•´å«å…³ç³»ã€‚
MultiRCï¼šåŸºäºå¤šå¥å­ä¸Šä¸‹æ–‡å›ç­”å¤šç­”æ¡ˆé—®é¢˜ã€‚
å®˜æ–¹é“¾æ¥ï¼šhttps://super.gluebenchmark.com/tasks
ä¸‹è½½æ–¹å¼
wget https://dl.fbaipublicfiles.com/glue/superglue/data/v2/combined.zip

2. CoQA æ•°æ®é›†
ä»»åŠ¡ç±»å‹ï¼šå¯¹è¯å¼é—®ç­”ï¼ˆQAï¼‰ï¼Œèšç„¦å¤šè½®å¯¹è¯ä¸­çš„ä¸Šä¸‹æ–‡è¿è´¯æ€§è¯„ä¼°ã€‚
æ•°æ®é›†è¯¦æƒ…ï¼š
åŒ…å« 8,000 å¤šä¸ªå¯¹è¯å’Œ 127,000 å¤šä¸ªé—®é¢˜ï¼Œè¦†ç›– 7 ä¸ªé¢†åŸŸã€‚
è¿‘åŠæ•°é—®é¢˜éœ€è¦æŒ‡ä»£æ¶ˆè§£å’Œè¯­ç”¨æ¨ç†ã€‚
å®˜æ–¹é“¾æ¥ï¼šhttps://stanfordnlp.github.io/coqa/
ä¸‹è½½æ–¹å¼ï¼š
wget https://nlp.stanford.edu/data/coqa/coqa-train-v1.0.json

3. XSum æ•°æ®é›†
ä»»åŠ¡ç±»å‹ï¼šæ‘˜è¦ç”Ÿæˆï¼Œè¯„ä¼°æ¨¡å‹å¯¹æ–°é—»æ–‡ç« çš„æç«¯å‹ç¼©èƒ½åŠ›ã€‚
æ•°æ®é›†è¯¦æƒ…ï¼š
åŒ…å« BBC æ–°é—»æ–‡ç« å’Œäººå·¥æ’°å†™çš„å•å¥æ‘˜è¦,è¦æ±‚æ¨¡å‹ç”Ÿæˆé«˜åº¦ç®€æ´çš„å•å¥æ‘˜è¦ã€‚
å®˜æ–¹é“¾æ¥ï¼šhttps://github.com/EdinburghNLP/XSum/tree/master
ä¸‹è½½æ–¹å¼ï¼š
#### é€šè¿‡ Hugging Face ä¸‹è½½
wget https://huggingface.co/datasets/EdinburghNLP/xsum/resolve/main/data/XSUM-EMNLP18-Summary-Data-Original.tar.gz?download=true
#### Xsumæ•°æ®æ‹†åˆ†
è¯¦è§ FedGLM-LLaMA/data/Xsum

### æ¨¡å‹å‡†å¤‡
1.ä¸‹è½½Llama 2æ¨¡å‹ï¼Œä¿å­˜è‡³ FL-LLaMa/Centralized_Models/model_path/
2.åˆ†å‰²æ¨¡å‹ python SplitModel.py --SplitA --SplitB --SplitC

### å¯åŠ¨æœåŠ¡
è®¾ç½®è„šæœ¬å‚æ•°
å·¥ä½œç›®å½•ï¼šFed-Llama-module
è¯·ä¿è¯å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ç«¯çš„å‚æ•°è®¾ç½®ä¸€è‡´ï¼Œä»¥ä¸‹çš„å‚æ•°åŠ¡å¿…ä¿æŒä¸€è‡´ï¼š

```bash
    --batch_size
    --learning_rate
    --max_output_length  
    --lora_r 
    --lora_alpha
    --target_modules
    --seed
    --max_source_length
    --max_target_length
    --modelA_layers
    --modelC_layers
    --server_ip
```

å°†æœåŠ¡å™¨ç«¯å’Œå®¢æˆ·ç«¯çš„æ¨¡å‹å‚æ•°è·¯å¾„æ”¹å†™å¥½ï¼š  
```python
modelA_name_or_path = "your_modelA_name_or_path"
modelB_name_or_path = "your_modelB_name_or_path"  
modelC_name_or_path = "your_modelC_name_or_path"
```

#### å•å®¢æˆ·ç«¯å¾®è°ƒï¼š
`./scripts/train.sh`  

ä»¥å®¢æˆ·ç«¯ä¸ºä¾‹ï¼š
``` bash
    cd ./Fed-Llama-module
    chmod +x ./scripts/train.sh
    bash ./scripts/train.sh
```
æ³¨æ„:
1. åœ¨å¯åŠ¨æœåŠ¡å‰ï¼Œè¯·å…ˆå°†æ‰€æœ‰çš„`'your_ip'`å­—æ®µä¿®æ”¹ä¸ºæ‚¨æœåŠ¡ç«¯ä¸æ¥æ”¶ç«¯çš„ipåœ°å€ã€‚
2. å¦‚æœä¸é€šè¿‡train.sh,æ‰‹åŠ¨å¯åŠ¨æœåŠ¡å™¨ç«¯å’Œå®¢æˆ·ç«¯ï¼Œæœ€å¥½ç­‰å¾…æœåŠ¡å™¨åé¦ˆ"Starting Flower server, config: ServerConfig(num_rounds=None, round_timeout=None)"åå†å¯åŠ¨å®¢æˆ·ç«¯ã€‚


#### å¤šå®¢æˆ·ç«¯å¾®è°ƒï¼š
`./scripts/train.sh`  

ä»¥å®¢æˆ·ç«¯ä¸ºä¾‹ï¼š
``` bash
    cd ./Fed-Llama-module
    chmod +x ./scripts/multi-train.sh
    bash ./scripts/multi-train.sh
```
æ³¨æ„:
1. åœ¨å¯åŠ¨æœåŠ¡å‰ï¼Œè¯·å…ˆå°†æ‰€æœ‰çš„`'your_ip'`å­—æ®µä¿®æ”¹ä¸ºæ‚¨æœåŠ¡ç«¯ä¸æ¥æ”¶ç«¯çš„ipåœ°å€ã€‚
2. å¦‚æœä¸é€šè¿‡train.sh,æ‰‹åŠ¨å¯åŠ¨æœåŠ¡å™¨ç«¯å’Œå®¢æˆ·ç«¯ï¼Œæœ€å¥½ç­‰å¾…æœåŠ¡å™¨åé¦ˆ"Starting Flower server, config: ServerConfig(num_rounds=None, round_timeout=None)"åå†å¯åŠ¨å®¢æˆ·ç«¯ã€‚

#### æ¨ç†ï¼š

```bash
    cd ./Fed-Llama-module
    chmod +x ./scripts/inference.sh
    bash ./scripts/inference.sh
```
æ³¨æ„:
1. åœ¨å¯åŠ¨æœåŠ¡å‰ï¼Œè¯·å…ˆå°†æ‰€æœ‰çš„`'your_ip'`å­—æ®µä¿®æ”¹ä¸ºæ‚¨æœåŠ¡ç«¯ä¸æ¥æ”¶ç«¯çš„ipåœ°å€ã€‚
2. å¦‚æœä¸é€šè¿‡train.sh,æ‰‹åŠ¨å¯åŠ¨æœåŠ¡å™¨ç«¯å’Œå®¢æˆ·ç«¯ï¼Œæœ€å¥½ç­‰å¾…æœåŠ¡å™¨åé¦ˆ"Starting Flower server, config: ServerConfig(num_rounds=None, round_timeout=None)"åå†å¯åŠ¨å®¢æˆ·ç«¯ã€‚
#### ç»“æŸæœåŠ¡
ç»“æŸåï¼Œæ‰‹åŠ¨å…³é—­ç»ˆç«¯ã€‚

## TODO
åŠ å…¥æ–­ç‚¹ç»­è®­ï¼Œç›®å‰æš‚ä¸æ”¯æŒ

## å¼•ç”¨ 
å¦‚æœä½ è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œæœ‰å¸®åŠ©çš„è¯ï¼Œè¯·å¼•ç”¨å¦‚ä¸‹è®ºæ–‡ã€‚
```
@misc{zheng2024safelylearningprivatedata,
      title={Safely Learning with Private Data: A Federated Learning Framework for Large Language Model}, 
      author={JiaYing Zheng and HaiNan Zhang and LingXiang Wang and WangJie Qiu and HongWei Zheng and ZhiMing Zheng},
      year={2024},
      eprint={2406.14898},
      archivePrefix={arXiv},
      primaryClass={cs.CR},
      url={https://arxiv.org/abs/2406.14898}, 
}
```