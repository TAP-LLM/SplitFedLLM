# SplitFedLLM
![transformers](https://img.shields.io/badge/transformers->=4.38.0-blue)
![License](https://img.shields.io/badge/license-MIT-yellow)  

 Read this in [English](README_en.md)

## é¡¹ç›®ä»‹ç»
æœ¬å¼€æºé¡¹ç›®åŸºäºå¼€æºçš„LLAMAå’ŒGLMæ¨¡å‹ï¼Œå®ç°äº†å•æœº/å¤šæœºéƒ¨ç½²çš„åˆ†å¸ƒå¼è”é‚¦å­¦ä¹ æ¡†æ¶å¯¹æ¨¡å‹è¿›è¡Œå¾®è°ƒä»¥åŠæ¨ç†,  
åœ¨ä¿è¯å®¢æˆ·ç«¯æ•°æ®éšç§å®‰å…¨çš„åŒæ—¶ï¼Œå®ç°æ¨¡å‹å‚æ•°çš„èšåˆï¼Œä»è€Œå®ç°æ¨¡å‹å‚æ•°çš„å…±äº«ã€‚ä½¿å¾—ç”¨æˆ·å¯ä»¥åœ¨è‡ªèº«ç®—åŠ›  
æœ‰é™çš„æƒ…å†µä¸‹åˆ©ç”¨é¡¹ç›®éƒ¨ç½²å¹³å°çš„èµ„æºç«¯è¿›è¡Œæ¨¡å‹å¾®è°ƒï¼Œä»è€Œå®ç°æ¨¡å‹çš„å‚ç›´é¢†åŸŸå®šåˆ¶åŒ–ã€‚

## æ”¯æŒçš„æ¨¡å‹
| Model            | Type | Download                                                                                                                                |
|------------------|------|-----------------------------------------------------------------------------------------------------------------------------------------|                                                                                                                                                                                         
| Llama-2-7b-hf    | Chat | [ğŸ¤— Huggingface](https://huggingface.co/meta-llama/Llama-2-7b-hf)  |
| Llama-2-7b-chat-hf | Chat | [ğŸ¤— Huggingface](https://huggingface.co/meta-llama/Llama-2-7b-chat-hf)                                                                                                                                                                                          |

## å¿«é€Ÿå¼€å§‹

### å®‰è£…ä¾èµ–é¡¹
```bash
git clone https://github.com/TAP-LLM/SplitFedLLM.git
cd SplitFedLLM
pip install -e .
```
### æ•°æ®å‡†å¤‡

è¯·å°†è®­ç»ƒæ•°æ®é›†æŒ‰ç…§ç¤ºä¾‹æ–‡ä»¶æ ¼å¼è¿›è¡Œæ•´ç†ï¼ˆä¸€ä¸ªå•åˆ—çš„csvæ–‡ä»¶ï¼Œè¾“å…¥æ•´ä½“æ˜¯ä¸€å¥è¯ï¼Œå…¶ä¸­çš„ç‰¹æ®Štokençš„ä½¿ç”¨ä¹Ÿç¬¦åˆæ–‡ä»¶ç¤ºä¾‹ï¼š/data/train_test.csvï¼‰

### è®¾ç½®è„šæœ¬å‚æ•°

è¯·å°½å¯èƒ½ä¿è¯å®¢æˆ·ç«¯å’ŒæœåŠ¡å™¨ç«¯çš„å‚æ•°è®¾ç½®ä¸€è‡´ï¼ˆåç»­å¯ä»¥è¿›è¡Œé€šä¿¡ä¼ é€’ï¼‰ï¼Œä»¥ä¸‹çš„å‚æ•°åŠ¡å¿…ä¿æŒä¸€è‡´ï¼š  
```bash
    --learning_rate  
    --num_train_epochs
    --warmup_steps 
    --load_in_bits
    --lora_r 
    --lora_alpha
    --target_modules
    --seed
    --block_size
    --deepspeed ds_config_zero2.json # deepspeedé…ç½®æ–‡ä»¶å¤ç”¨
    --bf16  
```


å®¢æˆ·ç«¯çš„--master_port='29501'å¦‚æœå•æœºæµ‹è¯•ä¸è¦æ”¹å›29500  


### é€šä¿¡


#### å¯åŠ¨æœåŠ¡
##### å¾®è°ƒï¼š
å®¢æˆ·ç«¯ï¼š./finetune/sft-client  
æœåŠ¡å™¨ï¼š./finetune/sft-service
å®¢æˆ·ç«¯ï¼ŒæœåŠ¡å™¨ç«¯éƒ½æ˜¯ä»¥å¯åŠ¨è„šæœ¬çš„æ–¹å¼å¯åŠ¨  
ä»¥å®¢æˆ·ç«¯ä¸ºä¾‹ï¼š
``` bash
    cd ./finetune/sft-client
    chmod +x ./finetune/sft-client/finetune.sh
    sh ./finetune/sft-client/finetune.sh/finetune.sh
```
æ³¨æ„è¯·å…ˆå¯åŠ¨æœåŠ¡å™¨ç«¯ï¼Œæœ€å¥½ç­‰å¾…æœåŠ¡å™¨åé¦ˆ"ç­‰å¾…æ¥æ”¶"åå†å¯åŠ¨å®¢æˆ·ç«¯


##### æ¨ç†ï¼š
å®¢æˆ·ç«¯ï¼š./eval/test-client  
æœåŠ¡å™¨ï¼š./eval/test-service  
å°†æœåŠ¡å™¨ç«¯å’Œå®¢æˆ·ç«¯çš„æ¨¡å‹å‚æ•°è·¯å¾„æ”¹å†™å¥½ï¼š  
```python
finetune_model_path = "your_finetune_model_path"  # loraå‚æ•°
base_model = "your_base_model_path"  # åŸæ¨¡å‹å‚æ•°
```
```bash
python test_lora_model.py  # ä¹Ÿæ˜¯å…ˆè¿è¡ŒæœåŠ¡å™¨ç«¯ï¼Œåœ¨æç¤ºï¼šâ€œæœåŠ¡å™¨ç«¯å·²å‡†å¤‡å°±ç»ªâ€åå¯åŠ¨å®¢æˆ·ç«¯
```
#### ç»“æŸæœåŠ¡
ç»“æŸåï¼Œæ‰‹åŠ¨å…³é—­ç»ˆç«¯ã€‚

## TODO
åŠ å…¥æ–­ç‚¹ç»­è®­ï¼Œç›®å‰æš‚ä¸æ”¯æŒ