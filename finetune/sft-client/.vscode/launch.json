{
    "version": "0.2.0",
    "configurations": [
        {
            "name": "Python: 当前文件",
            "type": "python",
            "request": "launch",
            "program": "finetune_clm_lora.py",
            "console": "integratedTerminal",
            "justMyCode": true,
            "args": [
                "--model_name_or_path",
                "/home/wanglingxiang/llama2_lora/model/Llama-2-7b-hf",
                "--train_files",
                "/home/wanglingxiang/llama2_lora/data/train_test.csv",
                "--validation_files",
                "/home/wanglingxiang/llama2_lora/data/train_test.csv",
                "--per_device_train_batch_size",
                "1",
                "--per_device_eval_batch_size",
                "1",
                "--do_train",
                "--do_eval",
                "--use_fast_tokenizer",
                "false",
                "--output_dir",
                "/home/wanglingxiang/llama2_lora/model/sft_test_1",
                "--evaluation_strategy",
                "steps",
                "--max_eval_samples",
                "800",
                "--learning_rate",
                "1e-4",
                "--gradient_accumulation_steps",
                "16",
                "--num_train_epochs",
                "10",
                "--warmup_steps",
                "400",
                "--load_in_bits",
                "4",
                "--lora_r",
                "4",
                "--lora_alpha",
                "32",
                "--target_modules",
                "q_proj,k_proj,v_proj,o_proj",
                "--logging_dir",
                "/home/wanglingxiang/llama2_lora/model/sft_test_1/logs",
                "--logging_strategy",
                "steps",
                "--logging_steps",
                "2000",
                "--save_strategy",
                "steps",
                "--preprocessing_num_workers",
                "10",
                "--save_steps",
                "1",
                "--eval_steps",
                "10",
                "--save_total_limit",
                "2000",
                "--seed",
                "42",
                "--disable_tqdm",
                "false",
                "--ddp_find_unused_parameters",
                "false",
                "--block_size",
                "4096",
                "--report_to",
                "tensorboard",
                "--overwrite_output_dir",
                "--deepspeed",
                "ds_config_zero2.json",
                "--ignore_data_skip",
                "true",
                "--bf16",
                "--gradient_checkpointing",
                "--bf16_full_eval",
                "--ddp_timeout",
                "18000000"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
            }
        }
    ]
}